{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dowhy import CausalModel \n",
    "import dowhy.datasets\n",
    "from utils.neo4j_connector import Neo4jConnector\n",
    "from utils.nx_neo4j_adapter import neo4j_to_nx \n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import statsmodels.api as sm\n",
    "import networkx as nx\n",
    "import io\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(num_samples, config):\n",
    "    \n",
    "    \n",
    "    data = dowhy.datasets.linear_dataset(10, \n",
    "                                        num_common_causes=config['num_common_causes'], \n",
    "                                        num_samples=num_samples,\n",
    "                                        num_instruments=config['num_instruments'], \n",
    "                                        num_effect_modifiers=config['num_effect_modifiers'],\n",
    "                                        num_treatments=config['num_treatments'],\n",
    "                                        num_frontdoor_variables=config['num_frontdoor_variables'],\n",
    "                                        treatment_is_binary=False,\n",
    "                                        outcome_is_binary=False)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = generate_data(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dag \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgml_graph\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# Get DAG in GML format\u001b[39;00m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mparse_gml(dag)  \u001b[38;5;66;03m# Parse GML to networkx graph\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Draw the graph\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "dag = data[\"gml_graph\"]  # Get DAG in GML format\n",
    "model = nx.parse_gml(dag)  # Parse GML to networkx graph\n",
    "\n",
    "# Draw the graph\n",
    "plt.figure(figsize=(6, 4))\n",
    "pos = nx.spring_layout(model)  # Positions for nodes\n",
    "nx.draw(model, pos, with_labels=True, node_color='lightblue', edge_color='gray', node_size=3000, font_size=12)\n",
    "plt.title(\"Causal DAG\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          FD0         FD1         FD2         FD3         FD4        X0  \\\n",
      "0   46.703625   79.261018   35.235795   88.011539   83.491488 -0.513396   \n",
      "1   93.042131   81.989401   71.367850  136.930723   90.830291  0.498215   \n",
      "2  293.250641  283.904629  237.934152  391.187318  352.526042 -0.173385   \n",
      "3  -47.889363  -44.892826  -40.393096  -51.065180  -57.779603  1.001225   \n",
      "4  184.630780  188.953227  146.405332  251.447548  229.836791  1.317250   \n",
      "\n",
      "         X1        X2        X3        X4  ...        W1        W2        W3  \\\n",
      "0  0.277021 -1.344686  1.051081 -0.701712  ... -1.641741  1.573732 -2.437798   \n",
      "1  0.655950 -0.863396 -0.572251 -0.324069  ... -1.353549 -0.760344  0.270836   \n",
      "2  2.845904 -1.225743  1.551034 -0.884633  ...  0.120778  0.592307  0.031958   \n",
      "3 -0.864010 -0.552103  1.166176  2.108267  ... -0.896505  1.271769 -0.020280   \n",
      "4 -0.374693 -0.582884 -0.285806 -0.057130  ... -0.030849  0.312291 -0.919708   \n",
      "\n",
      "         W4         v0         v1         v2         v3         v4  \\\n",
      "0 -1.817508  -0.596773  15.940475   4.097565   1.833321   2.982725   \n",
      "1 -0.535725  13.064967   8.058139   5.844218   7.085847   5.446684   \n",
      "2  2.292817  26.817179  16.193606  29.837949  24.002869  29.924398   \n",
      "3 -1.042927  -2.471183  -1.826603  -6.309870  -5.552611  -4.282208   \n",
      "4  0.562937  15.444647  13.424941  18.557044  15.005109  18.769389   \n",
      "\n",
      "              y  \n",
      "0  2.865350e+03  \n",
      "1  1.993985e+04  \n",
      "2  6.195464e+07  \n",
      "3 -5.235932e+03  \n",
      "4  1.571494e+06  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "df = data[\"df\"]\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dag_to_neo4j(G):\n",
    "    \n",
    "    # Convert to Cypher statements\n",
    "    cypher_statements = []\n",
    "    for node in G.nodes(data=True):\n",
    "        cypher_statements.append(f\"CREATE (n:CausalVariable {{name: '{node[0]}'}});\")\n",
    "\n",
    "    for edge in G.edges(data=True):\n",
    "        cypher_statements.append(f\"MATCH (a:CausalVariable {{name: '{edge[0]}'}}), (b:CausalVariable {{name: '{edge[1]}'}}) CREATE (a)-[:CAUSALLY_LINKED]->(b);\")\n",
    "\n",
    "    # Save to a file\n",
    "    with open(\"import_dag.cypher\", \"w\") as f:\n",
    "        f.write(\"\\n\".join(cypher_statements))\n",
    "        \n",
    "    try:\n",
    "        os.system('/Users/amedeo/Downloads/neo4j-community-5.12.0/bin/cypher-shell -u neo4j -p neo4j -f ./import_dag.cypher')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    print(\"Cypher export completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cypher export completed!\n"
     ]
    }
   ],
   "source": [
    "dag_to_neo4j(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_neo4j(df, G):\n",
    "    cypher_statements = []\n",
    "    columns = data['df'].columns.tolist()\n",
    "    for index, row in data['df'].iterrows():\n",
    "        for col in columns:\n",
    "            cypher_statements.append(f\"CREATE (n:{col} {{id: '{col+'_'+str(index)}', value: {row[col]}}});\")\n",
    "\n",
    "    \n",
    "\n",
    "    for index, row in data['df'].iterrows():\n",
    "        for edge in G.edges():\n",
    "    \n",
    "            cypher_statements.append(f\"MATCH (a: {edge[0]} {{id:'{edge[0]+'_'+str(index)}'}}), (b: {edge[1]} {{id:'{edge[1]+'_'+str(index)}'}}) CREATE (a)-[:REL]->(b);\")\n",
    "    \n",
    "    # Save to a file\n",
    "    with open(\"import_data.cypher\", \"w\") as f:\n",
    "        f.write(\"\\n\".join(cypher_statements))\n",
    "\n",
    "    try:\n",
    "        os.system('/Users/amedeo/Downloads/neo4j-community-5.12.0/bin/cypher-shell -u neo4j -p neo4j -f ./import_data.cypher')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    print(\"Cypher export completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cypher export completed!\n"
     ]
    }
   ],
   "source": [
    "data_to_neo4j(df, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def materialize_views_from_data(G):\n",
    "    cypher_statements=[]\n",
    "    for node in G.nodes(data=True):\n",
    "        \n",
    "        cypher_statements.append(f\"MATCH (a:{node[0]}), (cv:CausalVariable {{name: '{node[0]}'}}) CREATE (a)-[:BELONGS]->(cv);\")\n",
    "    \n",
    "    # Save to a file\n",
    "    with open(\"merge.cypher\", \"w\") as f:\n",
    "        f.write(\"\\n\".join(cypher_statements))\n",
    "        \n",
    "    try:\n",
    "        os.system('/Users/amedeo/Downloads/neo4j-community-5.12.0/bin/cypher-shell -u neo4j -p neo4j -f ./merge.cypher')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    print(\"Cypher export completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cypher export completed!\n",
      "1.548238754272461\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "materialize_views_from_data(model)\n",
    "t1 = time.time()\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediator_analysis(neo4jConnector):\n",
    "    mediators = neo4jConnector.query(\"MATCH (x:CausalVariable)-[:CAUSALLY_LINKED]->(m:CausalVariable)-[:CAUSALLY_LINKED]->(y:CausalVariable) WHERE NOT EXISTS { (x)-[:CAUSALLY_LINKED]->(y) WHERE x <> m } RETURN DISTINCT m AS Mediator, COLLECT([x, y]) AS Paths_Involved\")\n",
    "    return mediators\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "neo4jConnector = Neo4jConnector(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "neo4jConnector.clearNeo4j()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009908914566040039\n",
      "Mediator: FD0\n",
      "Paths involved:\n",
      "v0 -> FD0 -> y\n",
      "v1 -> FD0 -> y\n",
      "v2 -> FD0 -> y\n",
      "v3 -> FD0 -> y\n",
      "v4 -> FD0 -> y\n",
      "Mediator: FD1\n",
      "Paths involved:\n",
      "v0 -> FD1 -> y\n",
      "v1 -> FD1 -> y\n",
      "v2 -> FD1 -> y\n",
      "v3 -> FD1 -> y\n",
      "v4 -> FD1 -> y\n",
      "Mediator: FD2\n",
      "Paths involved:\n",
      "v0 -> FD2 -> y\n",
      "v1 -> FD2 -> y\n",
      "v2 -> FD2 -> y\n",
      "v3 -> FD2 -> y\n",
      "v4 -> FD2 -> y\n",
      "Mediator: FD3\n",
      "Paths involved:\n",
      "v0 -> FD3 -> y\n",
      "v1 -> FD3 -> y\n",
      "v2 -> FD3 -> y\n",
      "v3 -> FD3 -> y\n",
      "v4 -> FD3 -> y\n",
      "Mediator: FD4\n",
      "Paths involved:\n",
      "v0 -> FD4 -> y\n",
      "v1 -> FD4 -> y\n",
      "v2 -> FD4 -> y\n",
      "v3 -> FD4 -> y\n",
      "v4 -> FD4 -> y\n",
      "Mediator: v0\n",
      "Paths involved:\n",
      "Z0 -> v0 -> FD0\n",
      "Z1 -> v0 -> FD0\n",
      "Z0 -> v0 -> FD1\n",
      "Z1 -> v0 -> FD1\n",
      "Z0 -> v0 -> FD2\n",
      "Z1 -> v0 -> FD2\n",
      "Z0 -> v0 -> FD3\n",
      "Z1 -> v0 -> FD3\n",
      "Z0 -> v0 -> FD4\n",
      "Z1 -> v0 -> FD4\n",
      "Mediator: v1\n",
      "Paths involved:\n",
      "Z0 -> v1 -> FD0\n",
      "Z1 -> v1 -> FD0\n",
      "Z0 -> v1 -> FD1\n",
      "Z1 -> v1 -> FD1\n",
      "Z0 -> v1 -> FD2\n",
      "Z1 -> v1 -> FD2\n",
      "Z0 -> v1 -> FD3\n",
      "Z1 -> v1 -> FD3\n",
      "Z0 -> v1 -> FD4\n",
      "Z1 -> v1 -> FD4\n",
      "Mediator: v2\n",
      "Paths involved:\n",
      "Z0 -> v2 -> FD0\n",
      "Z1 -> v2 -> FD0\n",
      "Z0 -> v2 -> FD1\n",
      "Z1 -> v2 -> FD1\n",
      "Z0 -> v2 -> FD2\n",
      "Z1 -> v2 -> FD2\n",
      "Z0 -> v2 -> FD3\n",
      "Z1 -> v2 -> FD3\n",
      "Z0 -> v2 -> FD4\n",
      "Z1 -> v2 -> FD4\n",
      "Mediator: v3\n",
      "Paths involved:\n",
      "Z0 -> v3 -> FD0\n",
      "Z1 -> v3 -> FD0\n",
      "Z0 -> v3 -> FD1\n",
      "Z1 -> v3 -> FD1\n",
      "Z0 -> v3 -> FD2\n",
      "Z1 -> v3 -> FD2\n",
      "Z0 -> v3 -> FD3\n",
      "Z1 -> v3 -> FD3\n",
      "Z0 -> v3 -> FD4\n",
      "Z1 -> v3 -> FD4\n",
      "Mediator: v4\n",
      "Paths involved:\n",
      "Z0 -> v4 -> FD0\n",
      "Z1 -> v4 -> FD0\n",
      "Z0 -> v4 -> FD1\n",
      "Z1 -> v4 -> FD1\n",
      "Z0 -> v4 -> FD2\n",
      "Z1 -> v4 -> FD2\n",
      "Z0 -> v4 -> FD3\n",
      "Z1 -> v4 -> FD3\n",
      "Z0 -> v4 -> FD4\n",
      "Z1 -> v4 -> FD4\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "mediators = mediator_analysis(neo4jConnector)\n",
    "t1 = time.time()\n",
    "print(t1-t0)\n",
    "for record in mediators:\n",
    "    mediator = record['Mediator']\n",
    "    paths = record['Paths_Involved']\n",
    "    print(f\"Mediator: {mediator['name']}\")\n",
    "    print(\"Paths involved:\")\n",
    "    for path in paths:\n",
    "        print(f\"{path[0]['name']} -> {mediator['name']} -> {path[1]['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strict_confounders_analysis(neo4jConnector):\n",
    "    confounders = neo4jConnector.query(\"\"\"\n",
    "            MATCH (u:CausalVariable)-[:CAUSALLY_LINKED]->(x:CausalVariable), (u:CausalVariable)-[:CAUSALLY_LINKED]->(y:CausalVariable)\n",
    "            WHERE EXISTS { (x)-[:CAUSALLY_LINKED]->(y) }  // Ensure X affects Y\n",
    "            AND NOT EXISTS { \n",
    "                MATCH path = (x)-[:CAUSALLY_LINKED*1..]->(y)  // Find paths from X to Y\n",
    "                WHERE u IN nodes(path)  // Ensure U is NOT in any path from X to Y (not a mediator)\n",
    "                RETURN path\n",
    "            }\n",
    "            AND NOT EXISTS { (x)-[:CAUSALLY_LINKED]->(u) }  // Ensure X does NOT affect U\n",
    "            RETURN DISTINCT u AS Confounder, \n",
    "            COLLECT(DISTINCT [x, y]) AS Confounded_Paths\n",
    "    \"\"\")\n",
    "    return confounders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.020210981369018555\n",
      "Confounder: W0\n",
      "Paths involved:\n",
      "v0 -> FD0\n",
      "v0 -> FD1\n",
      "v0 -> FD2\n",
      "v0 -> FD3\n",
      "v0 -> FD4\n",
      "v1 -> FD0\n",
      "v1 -> FD1\n",
      "v1 -> FD2\n",
      "v1 -> FD3\n",
      "v1 -> FD4\n",
      "v2 -> FD0\n",
      "v2 -> FD1\n",
      "v2 -> FD2\n",
      "v2 -> FD3\n",
      "v2 -> FD4\n",
      "v3 -> FD0\n",
      "v3 -> FD1\n",
      "v3 -> FD2\n",
      "v3 -> FD3\n",
      "v3 -> FD4\n",
      "v4 -> FD0\n",
      "v4 -> FD1\n",
      "v4 -> FD2\n",
      "v4 -> FD3\n",
      "v4 -> FD4\n",
      "FD0 -> y\n",
      "FD1 -> y\n",
      "FD2 -> y\n",
      "FD3 -> y\n",
      "FD4 -> y\n",
      "Confounder: W1\n",
      "Paths involved:\n",
      "v0 -> FD0\n",
      "v0 -> FD1\n",
      "v0 -> FD2\n",
      "v0 -> FD3\n",
      "v0 -> FD4\n",
      "v1 -> FD0\n",
      "v1 -> FD1\n",
      "v1 -> FD2\n",
      "v1 -> FD3\n",
      "v1 -> FD4\n",
      "v2 -> FD0\n",
      "v2 -> FD1\n",
      "v2 -> FD2\n",
      "v2 -> FD3\n",
      "v2 -> FD4\n",
      "v3 -> FD0\n",
      "v3 -> FD1\n",
      "v3 -> FD2\n",
      "v3 -> FD3\n",
      "v3 -> FD4\n",
      "v4 -> FD0\n",
      "v4 -> FD1\n",
      "v4 -> FD2\n",
      "v4 -> FD3\n",
      "v4 -> FD4\n",
      "FD0 -> y\n",
      "FD1 -> y\n",
      "FD2 -> y\n",
      "FD3 -> y\n",
      "FD4 -> y\n",
      "Confounder: W2\n",
      "Paths involved:\n",
      "v0 -> FD0\n",
      "v0 -> FD1\n",
      "v0 -> FD2\n",
      "v0 -> FD3\n",
      "v0 -> FD4\n",
      "v1 -> FD0\n",
      "v1 -> FD1\n",
      "v1 -> FD2\n",
      "v1 -> FD3\n",
      "v1 -> FD4\n",
      "v2 -> FD0\n",
      "v2 -> FD1\n",
      "v2 -> FD2\n",
      "v2 -> FD3\n",
      "v2 -> FD4\n",
      "v3 -> FD0\n",
      "v3 -> FD1\n",
      "v3 -> FD2\n",
      "v3 -> FD3\n",
      "v3 -> FD4\n",
      "v4 -> FD0\n",
      "v4 -> FD1\n",
      "v4 -> FD2\n",
      "v4 -> FD3\n",
      "v4 -> FD4\n",
      "FD0 -> y\n",
      "FD1 -> y\n",
      "FD2 -> y\n",
      "FD3 -> y\n",
      "FD4 -> y\n",
      "Confounder: W3\n",
      "Paths involved:\n",
      "v0 -> FD0\n",
      "v0 -> FD1\n",
      "v0 -> FD2\n",
      "v0 -> FD3\n",
      "v0 -> FD4\n",
      "v1 -> FD0\n",
      "v1 -> FD1\n",
      "v1 -> FD2\n",
      "v1 -> FD3\n",
      "v1 -> FD4\n",
      "v2 -> FD0\n",
      "v2 -> FD1\n",
      "v2 -> FD2\n",
      "v2 -> FD3\n",
      "v2 -> FD4\n",
      "v3 -> FD0\n",
      "v3 -> FD1\n",
      "v3 -> FD2\n",
      "v3 -> FD3\n",
      "v3 -> FD4\n",
      "v4 -> FD0\n",
      "v4 -> FD1\n",
      "v4 -> FD2\n",
      "v4 -> FD3\n",
      "v4 -> FD4\n",
      "FD0 -> y\n",
      "FD1 -> y\n",
      "FD2 -> y\n",
      "FD3 -> y\n",
      "FD4 -> y\n",
      "Confounder: W4\n",
      "Paths involved:\n",
      "v0 -> FD0\n",
      "v0 -> FD1\n",
      "v0 -> FD2\n",
      "v0 -> FD3\n",
      "v0 -> FD4\n",
      "v1 -> FD0\n",
      "v1 -> FD1\n",
      "v1 -> FD2\n",
      "v1 -> FD3\n",
      "v1 -> FD4\n",
      "v2 -> FD0\n",
      "v2 -> FD1\n",
      "v2 -> FD2\n",
      "v2 -> FD3\n",
      "v2 -> FD4\n",
      "v3 -> FD0\n",
      "v3 -> FD1\n",
      "v3 -> FD2\n",
      "v3 -> FD3\n",
      "v3 -> FD4\n",
      "v4 -> FD0\n",
      "v4 -> FD1\n",
      "v4 -> FD2\n",
      "v4 -> FD3\n",
      "v4 -> FD4\n",
      "FD0 -> y\n",
      "FD1 -> y\n",
      "FD2 -> y\n",
      "FD3 -> y\n",
      "FD4 -> y\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "confounders_not_mediators = strict_confounders_analysis(neo4jConnector)\n",
    "t1 = time.time()\n",
    "print(t1-t0)\n",
    "for record in confounders_not_mediators:\n",
    "    confounder = record['Confounder']\n",
    "    paths = record['Confounded_Paths']\n",
    "    print(f\"Confounder: {confounder['name']}\")\n",
    "    print(\"Paths involved:\")\n",
    "    for path in paths:\n",
    "        print(f\"{path[0]['name']} -> {path[1]['name']}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confounder_analysis(neo4jConnector):\n",
    "    confounders = neo4jConnector.query(\"\"\"\n",
    "            MATCH (u)-[:CAUSALLY_LINKED]->(x), (u)-[:CAUSALLY_LINKED]->(y)\n",
    "            WHERE EXISTS { (x)-[:CAUSALLY_LINKED]->(y) }\n",
    "            RETURN DISTINCT u AS Confounder, \n",
    "                COLLECT(DISTINCT [x, y]) AS Confounded_Paths\n",
    "\n",
    "    \"\"\")\n",
    "    return confounders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'neo4jConnector' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 2\u001b[0m confounders \u001b[38;5;241m=\u001b[39m strict_confounders_analysis(\u001b[43mneo4jConnector\u001b[49m)\n\u001b[1;32m      3\u001b[0m t1 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(t1\u001b[38;5;241m-\u001b[39mt0)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'neo4jConnector' is not defined"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "confounders = strict_confounders_analysis(neo4jConnector)\n",
    "t1 = time.time()\n",
    "print(t1-t0)\n",
    "for record in confounders:\n",
    "    confounder = record['Confounder']\n",
    "    paths = record['Confounded_Paths']\n",
    "    print(f\"Confounder: {confounder['name']}\")\n",
    "    print(\"Paths involved:\")\n",
    "    for path in paths:\n",
    "        print(f\"{path[0]['name']} -> {path[1]['name']}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collider_analysis(neo4jConnector):\n",
    "    confounders = neo4jConnector.query(\"\"\"\n",
    "            MATCH (x)-[:CAUSALLY_LINKED]->(c)<-[:CAUSALLY_LINKED]-(y)\n",
    "            WHERE NOT EXISTS { (x)-[:CAUSALLY_LINKED]->(y) }  // Ensure X and Y are NOT directly connected\n",
    "            RETURN DISTINCT c AS Collider, \n",
    "            COLLECT(DISTINCT [x, y]) AS Collider_Paths\n",
    "    \"\"\")\n",
    "    return confounders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03978705406188965\n",
      "Collider: v0\n",
      "Paths involved:\n",
      "W1 -> W0\n",
      "W2 -> W0\n",
      "W3 -> W0\n",
      "W4 -> W0\n",
      "Z0 -> W0\n",
      "Z1 -> W0\n",
      "W0 -> W1\n",
      "W2 -> W1\n",
      "W3 -> W1\n",
      "W4 -> W1\n",
      "Z0 -> W1\n",
      "Z1 -> W1\n",
      "W0 -> W2\n",
      "W1 -> W2\n",
      "W3 -> W2\n",
      "W4 -> W2\n",
      "Z0 -> W2\n",
      "Z1 -> W2\n",
      "W0 -> W3\n",
      "W1 -> W3\n",
      "W2 -> W3\n",
      "W4 -> W3\n",
      "Z0 -> W3\n",
      "Z1 -> W3\n",
      "W0 -> W4\n",
      "W1 -> W4\n",
      "W2 -> W4\n",
      "W3 -> W4\n",
      "Z0 -> W4\n",
      "Z1 -> W4\n",
      "W0 -> Z0\n",
      "W1 -> Z0\n",
      "W2 -> Z0\n",
      "W3 -> Z0\n",
      "W4 -> Z0\n",
      "Z1 -> Z0\n",
      "W0 -> Z1\n",
      "W1 -> Z1\n",
      "W2 -> Z1\n",
      "W3 -> Z1\n",
      "W4 -> Z1\n",
      "Z0 -> Z1\n",
      "Collider: v1\n",
      "Paths involved:\n",
      "W1 -> W0\n",
      "W2 -> W0\n",
      "W3 -> W0\n",
      "W4 -> W0\n",
      "Z0 -> W0\n",
      "Z1 -> W0\n",
      "W0 -> W1\n",
      "W2 -> W1\n",
      "W3 -> W1\n",
      "W4 -> W1\n",
      "Z0 -> W1\n",
      "Z1 -> W1\n",
      "W0 -> W2\n",
      "W1 -> W2\n",
      "W3 -> W2\n",
      "W4 -> W2\n",
      "Z0 -> W2\n",
      "Z1 -> W2\n",
      "W0 -> W3\n",
      "W1 -> W3\n",
      "W2 -> W3\n",
      "W4 -> W3\n",
      "Z0 -> W3\n",
      "Z1 -> W3\n",
      "W0 -> W4\n",
      "W1 -> W4\n",
      "W2 -> W4\n",
      "W3 -> W4\n",
      "Z0 -> W4\n",
      "Z1 -> W4\n",
      "W0 -> Z0\n",
      "W1 -> Z0\n",
      "W2 -> Z0\n",
      "W3 -> Z0\n",
      "W4 -> Z0\n",
      "Z1 -> Z0\n",
      "W0 -> Z1\n",
      "W1 -> Z1\n",
      "W2 -> Z1\n",
      "W3 -> Z1\n",
      "W4 -> Z1\n",
      "Z0 -> Z1\n",
      "Collider: v2\n",
      "Paths involved:\n",
      "W1 -> W0\n",
      "W2 -> W0\n",
      "W3 -> W0\n",
      "W4 -> W0\n",
      "Z0 -> W0\n",
      "Z1 -> W0\n",
      "W0 -> W1\n",
      "W2 -> W1\n",
      "W3 -> W1\n",
      "W4 -> W1\n",
      "Z0 -> W1\n",
      "Z1 -> W1\n",
      "W0 -> W2\n",
      "W1 -> W2\n",
      "W3 -> W2\n",
      "W4 -> W2\n",
      "Z0 -> W2\n",
      "Z1 -> W2\n",
      "W0 -> W3\n",
      "W1 -> W3\n",
      "W2 -> W3\n",
      "W4 -> W3\n",
      "Z0 -> W3\n",
      "Z1 -> W3\n",
      "W0 -> W4\n",
      "W1 -> W4\n",
      "W2 -> W4\n",
      "W3 -> W4\n",
      "Z0 -> W4\n",
      "Z1 -> W4\n",
      "W0 -> Z0\n",
      "W1 -> Z0\n",
      "W2 -> Z0\n",
      "W3 -> Z0\n",
      "W4 -> Z0\n",
      "Z1 -> Z0\n",
      "W0 -> Z1\n",
      "W1 -> Z1\n",
      "W2 -> Z1\n",
      "W3 -> Z1\n",
      "W4 -> Z1\n",
      "Z0 -> Z1\n",
      "Collider: v3\n",
      "Paths involved:\n",
      "W1 -> W0\n",
      "W2 -> W0\n",
      "W3 -> W0\n",
      "W4 -> W0\n",
      "Z0 -> W0\n",
      "Z1 -> W0\n",
      "W0 -> W1\n",
      "W2 -> W1\n",
      "W3 -> W1\n",
      "W4 -> W1\n",
      "Z0 -> W1\n",
      "Z1 -> W1\n",
      "W0 -> W2\n",
      "W1 -> W2\n",
      "W3 -> W2\n",
      "W4 -> W2\n",
      "Z0 -> W2\n",
      "Z1 -> W2\n",
      "W0 -> W3\n",
      "W1 -> W3\n",
      "W2 -> W3\n",
      "W4 -> W3\n",
      "Z0 -> W3\n",
      "Z1 -> W3\n",
      "W0 -> W4\n",
      "W1 -> W4\n",
      "W2 -> W4\n",
      "W3 -> W4\n",
      "Z0 -> W4\n",
      "Z1 -> W4\n",
      "W0 -> Z0\n",
      "W1 -> Z0\n",
      "W2 -> Z0\n",
      "W3 -> Z0\n",
      "W4 -> Z0\n",
      "Z1 -> Z0\n",
      "W0 -> Z1\n",
      "W1 -> Z1\n",
      "W2 -> Z1\n",
      "W3 -> Z1\n",
      "W4 -> Z1\n",
      "Z0 -> Z1\n",
      "Collider: v4\n",
      "Paths involved:\n",
      "W1 -> W0\n",
      "W2 -> W0\n",
      "W3 -> W0\n",
      "W4 -> W0\n",
      "Z0 -> W0\n",
      "Z1 -> W0\n",
      "W0 -> W1\n",
      "W2 -> W1\n",
      "W3 -> W1\n",
      "W4 -> W1\n",
      "Z0 -> W1\n",
      "Z1 -> W1\n",
      "W0 -> W2\n",
      "W1 -> W2\n",
      "W3 -> W2\n",
      "W4 -> W2\n",
      "Z0 -> W2\n",
      "Z1 -> W2\n",
      "W0 -> W3\n",
      "W1 -> W3\n",
      "W2 -> W3\n",
      "W4 -> W3\n",
      "Z0 -> W3\n",
      "Z1 -> W3\n",
      "W0 -> W4\n",
      "W1 -> W4\n",
      "W2 -> W4\n",
      "W3 -> W4\n",
      "Z0 -> W4\n",
      "Z1 -> W4\n",
      "W0 -> Z0\n",
      "W1 -> Z0\n",
      "W2 -> Z0\n",
      "W3 -> Z0\n",
      "W4 -> Z0\n",
      "Z1 -> Z0\n",
      "W0 -> Z1\n",
      "W1 -> Z1\n",
      "W2 -> Z1\n",
      "W3 -> Z1\n",
      "W4 -> Z1\n",
      "Z0 -> Z1\n",
      "Collider: y\n",
      "Paths involved:\n",
      "W1 -> W0\n",
      "W2 -> W0\n",
      "W3 -> W0\n",
      "W4 -> W0\n",
      "FD0 -> W0\n",
      "FD1 -> W0\n",
      "FD2 -> W0\n",
      "FD3 -> W0\n",
      "FD4 -> W0\n",
      "X0 -> W0\n",
      "X1 -> W0\n",
      "X2 -> W0\n",
      "X3 -> W0\n",
      "X4 -> W0\n",
      "W0 -> W1\n",
      "W2 -> W1\n",
      "W3 -> W1\n",
      "W4 -> W1\n",
      "FD0 -> W1\n",
      "FD1 -> W1\n",
      "FD2 -> W1\n",
      "FD3 -> W1\n",
      "FD4 -> W1\n",
      "X0 -> W1\n",
      "X1 -> W1\n",
      "X2 -> W1\n",
      "X3 -> W1\n",
      "X4 -> W1\n",
      "W0 -> W2\n",
      "W1 -> W2\n",
      "W3 -> W2\n",
      "W4 -> W2\n",
      "FD0 -> W2\n",
      "FD1 -> W2\n",
      "FD2 -> W2\n",
      "FD3 -> W2\n",
      "FD4 -> W2\n",
      "X0 -> W2\n",
      "X1 -> W2\n",
      "X2 -> W2\n",
      "X3 -> W2\n",
      "X4 -> W2\n",
      "W0 -> W3\n",
      "W1 -> W3\n",
      "W2 -> W3\n",
      "W4 -> W3\n",
      "FD0 -> W3\n",
      "FD1 -> W3\n",
      "FD2 -> W3\n",
      "FD3 -> W3\n",
      "FD4 -> W3\n",
      "X0 -> W3\n",
      "X1 -> W3\n",
      "X2 -> W3\n",
      "X3 -> W3\n",
      "X4 -> W3\n",
      "W0 -> W4\n",
      "W1 -> W4\n",
      "W2 -> W4\n",
      "W3 -> W4\n",
      "FD0 -> W4\n",
      "FD1 -> W4\n",
      "FD2 -> W4\n",
      "FD3 -> W4\n",
      "FD4 -> W4\n",
      "X0 -> W4\n",
      "X1 -> W4\n",
      "X2 -> W4\n",
      "X3 -> W4\n",
      "X4 -> W4\n",
      "FD1 -> FD0\n",
      "FD2 -> FD0\n",
      "FD3 -> FD0\n",
      "FD4 -> FD0\n",
      "X0 -> FD0\n",
      "X1 -> FD0\n",
      "X2 -> FD0\n",
      "X3 -> FD0\n",
      "X4 -> FD0\n",
      "FD0 -> FD1\n",
      "FD2 -> FD1\n",
      "FD3 -> FD1\n",
      "FD4 -> FD1\n",
      "X0 -> FD1\n",
      "X1 -> FD1\n",
      "X2 -> FD1\n",
      "X3 -> FD1\n",
      "X4 -> FD1\n",
      "FD0 -> FD2\n",
      "FD1 -> FD2\n",
      "FD3 -> FD2\n",
      "FD4 -> FD2\n",
      "X0 -> FD2\n",
      "X1 -> FD2\n",
      "X2 -> FD2\n",
      "X3 -> FD2\n",
      "X4 -> FD2\n",
      "FD0 -> FD3\n",
      "FD1 -> FD3\n",
      "FD2 -> FD3\n",
      "FD4 -> FD3\n",
      "X0 -> FD3\n",
      "X1 -> FD3\n",
      "X2 -> FD3\n",
      "X3 -> FD3\n",
      "X4 -> FD3\n",
      "FD0 -> FD4\n",
      "FD1 -> FD4\n",
      "FD2 -> FD4\n",
      "FD3 -> FD4\n",
      "X0 -> FD4\n",
      "X1 -> FD4\n",
      "X2 -> FD4\n",
      "X3 -> FD4\n",
      "X4 -> FD4\n",
      "W0 -> X0\n",
      "W1 -> X0\n",
      "W2 -> X0\n",
      "W3 -> X0\n",
      "W4 -> X0\n",
      "FD0 -> X0\n",
      "FD1 -> X0\n",
      "FD2 -> X0\n",
      "FD3 -> X0\n",
      "FD4 -> X0\n",
      "X1 -> X0\n",
      "X2 -> X0\n",
      "X3 -> X0\n",
      "X4 -> X0\n",
      "W0 -> X1\n",
      "W1 -> X1\n",
      "W2 -> X1\n",
      "W3 -> X1\n",
      "W4 -> X1\n",
      "FD0 -> X1\n",
      "FD1 -> X1\n",
      "FD2 -> X1\n",
      "FD3 -> X1\n",
      "FD4 -> X1\n",
      "X0 -> X1\n",
      "X2 -> X1\n",
      "X3 -> X1\n",
      "X4 -> X1\n",
      "W0 -> X2\n",
      "W1 -> X2\n",
      "W2 -> X2\n",
      "W3 -> X2\n",
      "W4 -> X2\n",
      "FD0 -> X2\n",
      "FD1 -> X2\n",
      "FD2 -> X2\n",
      "FD3 -> X2\n",
      "FD4 -> X2\n",
      "X0 -> X2\n",
      "X1 -> X2\n",
      "X3 -> X2\n",
      "X4 -> X2\n",
      "W0 -> X3\n",
      "W1 -> X3\n",
      "W2 -> X3\n",
      "W3 -> X3\n",
      "W4 -> X3\n",
      "FD0 -> X3\n",
      "FD1 -> X3\n",
      "FD2 -> X3\n",
      "FD3 -> X3\n",
      "FD4 -> X3\n",
      "X0 -> X3\n",
      "X1 -> X3\n",
      "X2 -> X3\n",
      "X4 -> X3\n",
      "W0 -> X4\n",
      "W1 -> X4\n",
      "W2 -> X4\n",
      "W3 -> X4\n",
      "W4 -> X4\n",
      "FD0 -> X4\n",
      "FD1 -> X4\n",
      "FD2 -> X4\n",
      "FD3 -> X4\n",
      "FD4 -> X4\n",
      "X0 -> X4\n",
      "X1 -> X4\n",
      "X2 -> X4\n",
      "X3 -> X4\n",
      "Collider: FD0\n",
      "Paths involved:\n",
      "W1 -> W0\n",
      "W2 -> W0\n",
      "W3 -> W0\n",
      "W4 -> W0\n",
      "v0 -> W0\n",
      "v1 -> W0\n",
      "v2 -> W0\n",
      "v3 -> W0\n",
      "v4 -> W0\n",
      "W0 -> W1\n",
      "W2 -> W1\n",
      "W3 -> W1\n",
      "W4 -> W1\n",
      "v0 -> W1\n",
      "v1 -> W1\n",
      "v2 -> W1\n",
      "v3 -> W1\n",
      "v4 -> W1\n",
      "W0 -> W2\n",
      "W1 -> W2\n",
      "W3 -> W2\n",
      "W4 -> W2\n",
      "v0 -> W2\n",
      "v1 -> W2\n",
      "v2 -> W2\n",
      "v3 -> W2\n",
      "v4 -> W2\n",
      "W0 -> W3\n",
      "W1 -> W3\n",
      "W2 -> W3\n",
      "W4 -> W3\n",
      "v0 -> W3\n",
      "v1 -> W3\n",
      "v2 -> W3\n",
      "v3 -> W3\n",
      "v4 -> W3\n",
      "W0 -> W4\n",
      "W1 -> W4\n",
      "W2 -> W4\n",
      "W3 -> W4\n",
      "v0 -> W4\n",
      "v1 -> W4\n",
      "v2 -> W4\n",
      "v3 -> W4\n",
      "v4 -> W4\n",
      "v1 -> v0\n",
      "v2 -> v0\n",
      "v3 -> v0\n",
      "v4 -> v0\n",
      "v0 -> v1\n",
      "v2 -> v1\n",
      "v3 -> v1\n",
      "v4 -> v1\n",
      "v0 -> v2\n",
      "v1 -> v2\n",
      "v3 -> v2\n",
      "v4 -> v2\n",
      "v0 -> v3\n",
      "v1 -> v3\n",
      "v2 -> v3\n",
      "v4 -> v3\n",
      "v0 -> v4\n",
      "v1 -> v4\n",
      "v2 -> v4\n",
      "v3 -> v4\n",
      "Collider: FD1\n",
      "Paths involved:\n",
      "W1 -> W0\n",
      "W2 -> W0\n",
      "W3 -> W0\n",
      "W4 -> W0\n",
      "v0 -> W0\n",
      "v1 -> W0\n",
      "v2 -> W0\n",
      "v3 -> W0\n",
      "v4 -> W0\n",
      "W0 -> W1\n",
      "W2 -> W1\n",
      "W3 -> W1\n",
      "W4 -> W1\n",
      "v0 -> W1\n",
      "v1 -> W1\n",
      "v2 -> W1\n",
      "v3 -> W1\n",
      "v4 -> W1\n",
      "W0 -> W2\n",
      "W1 -> W2\n",
      "W3 -> W2\n",
      "W4 -> W2\n",
      "v0 -> W2\n",
      "v1 -> W2\n",
      "v2 -> W2\n",
      "v3 -> W2\n",
      "v4 -> W2\n",
      "W0 -> W3\n",
      "W1 -> W3\n",
      "W2 -> W3\n",
      "W4 -> W3\n",
      "v0 -> W3\n",
      "v1 -> W3\n",
      "v2 -> W3\n",
      "v3 -> W3\n",
      "v4 -> W3\n",
      "W0 -> W4\n",
      "W1 -> W4\n",
      "W2 -> W4\n",
      "W3 -> W4\n",
      "v0 -> W4\n",
      "v1 -> W4\n",
      "v2 -> W4\n",
      "v3 -> W4\n",
      "v4 -> W4\n",
      "v1 -> v0\n",
      "v2 -> v0\n",
      "v3 -> v0\n",
      "v4 -> v0\n",
      "v0 -> v1\n",
      "v2 -> v1\n",
      "v3 -> v1\n",
      "v4 -> v1\n",
      "v0 -> v2\n",
      "v1 -> v2\n",
      "v3 -> v2\n",
      "v4 -> v2\n",
      "v0 -> v3\n",
      "v1 -> v3\n",
      "v2 -> v3\n",
      "v4 -> v3\n",
      "v0 -> v4\n",
      "v1 -> v4\n",
      "v2 -> v4\n",
      "v3 -> v4\n",
      "Collider: FD2\n",
      "Paths involved:\n",
      "W1 -> W0\n",
      "W2 -> W0\n",
      "W3 -> W0\n",
      "W4 -> W0\n",
      "v0 -> W0\n",
      "v1 -> W0\n",
      "v2 -> W0\n",
      "v3 -> W0\n",
      "v4 -> W0\n",
      "W0 -> W1\n",
      "W2 -> W1\n",
      "W3 -> W1\n",
      "W4 -> W1\n",
      "v0 -> W1\n",
      "v1 -> W1\n",
      "v2 -> W1\n",
      "v3 -> W1\n",
      "v4 -> W1\n",
      "W0 -> W2\n",
      "W1 -> W2\n",
      "W3 -> W2\n",
      "W4 -> W2\n",
      "v0 -> W2\n",
      "v1 -> W2\n",
      "v2 -> W2\n",
      "v3 -> W2\n",
      "v4 -> W2\n",
      "W0 -> W3\n",
      "W1 -> W3\n",
      "W2 -> W3\n",
      "W4 -> W3\n",
      "v0 -> W3\n",
      "v1 -> W3\n",
      "v2 -> W3\n",
      "v3 -> W3\n",
      "v4 -> W3\n",
      "W0 -> W4\n",
      "W1 -> W4\n",
      "W2 -> W4\n",
      "W3 -> W4\n",
      "v0 -> W4\n",
      "v1 -> W4\n",
      "v2 -> W4\n",
      "v3 -> W4\n",
      "v4 -> W4\n",
      "v1 -> v0\n",
      "v2 -> v0\n",
      "v3 -> v0\n",
      "v4 -> v0\n",
      "v0 -> v1\n",
      "v2 -> v1\n",
      "v3 -> v1\n",
      "v4 -> v1\n",
      "v0 -> v2\n",
      "v1 -> v2\n",
      "v3 -> v2\n",
      "v4 -> v2\n",
      "v0 -> v3\n",
      "v1 -> v3\n",
      "v2 -> v3\n",
      "v4 -> v3\n",
      "v0 -> v4\n",
      "v1 -> v4\n",
      "v2 -> v4\n",
      "v3 -> v4\n",
      "Collider: FD3\n",
      "Paths involved:\n",
      "W1 -> W0\n",
      "W2 -> W0\n",
      "W3 -> W0\n",
      "W4 -> W0\n",
      "v0 -> W0\n",
      "v1 -> W0\n",
      "v2 -> W0\n",
      "v3 -> W0\n",
      "v4 -> W0\n",
      "W0 -> W1\n",
      "W2 -> W1\n",
      "W3 -> W1\n",
      "W4 -> W1\n",
      "v0 -> W1\n",
      "v1 -> W1\n",
      "v2 -> W1\n",
      "v3 -> W1\n",
      "v4 -> W1\n",
      "W0 -> W2\n",
      "W1 -> W2\n",
      "W3 -> W2\n",
      "W4 -> W2\n",
      "v0 -> W2\n",
      "v1 -> W2\n",
      "v2 -> W2\n",
      "v3 -> W2\n",
      "v4 -> W2\n",
      "W0 -> W3\n",
      "W1 -> W3\n",
      "W2 -> W3\n",
      "W4 -> W3\n",
      "v0 -> W3\n",
      "v1 -> W3\n",
      "v2 -> W3\n",
      "v3 -> W3\n",
      "v4 -> W3\n",
      "W0 -> W4\n",
      "W1 -> W4\n",
      "W2 -> W4\n",
      "W3 -> W4\n",
      "v0 -> W4\n",
      "v1 -> W4\n",
      "v2 -> W4\n",
      "v3 -> W4\n",
      "v4 -> W4\n",
      "v1 -> v0\n",
      "v2 -> v0\n",
      "v3 -> v0\n",
      "v4 -> v0\n",
      "v0 -> v1\n",
      "v2 -> v1\n",
      "v3 -> v1\n",
      "v4 -> v1\n",
      "v0 -> v2\n",
      "v1 -> v2\n",
      "v3 -> v2\n",
      "v4 -> v2\n",
      "v0 -> v3\n",
      "v1 -> v3\n",
      "v2 -> v3\n",
      "v4 -> v3\n",
      "v0 -> v4\n",
      "v1 -> v4\n",
      "v2 -> v4\n",
      "v3 -> v4\n",
      "Collider: FD4\n",
      "Paths involved:\n",
      "W1 -> W0\n",
      "W2 -> W0\n",
      "W3 -> W0\n",
      "W4 -> W0\n",
      "v0 -> W0\n",
      "v1 -> W0\n",
      "v2 -> W0\n",
      "v3 -> W0\n",
      "v4 -> W0\n",
      "W0 -> W1\n",
      "W2 -> W1\n",
      "W3 -> W1\n",
      "W4 -> W1\n",
      "v0 -> W1\n",
      "v1 -> W1\n",
      "v2 -> W1\n",
      "v3 -> W1\n",
      "v4 -> W1\n",
      "W0 -> W2\n",
      "W1 -> W2\n",
      "W3 -> W2\n",
      "W4 -> W2\n",
      "v0 -> W2\n",
      "v1 -> W2\n",
      "v2 -> W2\n",
      "v3 -> W2\n",
      "v4 -> W2\n",
      "W0 -> W3\n",
      "W1 -> W3\n",
      "W2 -> W3\n",
      "W4 -> W3\n",
      "v0 -> W3\n",
      "v1 -> W3\n",
      "v2 -> W3\n",
      "v3 -> W3\n",
      "v4 -> W3\n",
      "W0 -> W4\n",
      "W1 -> W4\n",
      "W2 -> W4\n",
      "W3 -> W4\n",
      "v0 -> W4\n",
      "v1 -> W4\n",
      "v2 -> W4\n",
      "v3 -> W4\n",
      "v4 -> W4\n",
      "v1 -> v0\n",
      "v2 -> v0\n",
      "v3 -> v0\n",
      "v4 -> v0\n",
      "v0 -> v1\n",
      "v2 -> v1\n",
      "v3 -> v1\n",
      "v4 -> v1\n",
      "v0 -> v2\n",
      "v1 -> v2\n",
      "v3 -> v2\n",
      "v4 -> v2\n",
      "v0 -> v3\n",
      "v1 -> v3\n",
      "v2 -> v3\n",
      "v4 -> v3\n",
      "v0 -> v4\n",
      "v1 -> v4\n",
      "v2 -> v4\n",
      "v3 -> v4\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "confounders = collider_analysis(neo4jConnector)\n",
    "t1 = time.time()\n",
    "print(t1-t0)\n",
    "for record in confounders:\n",
    "    confounder = record['Collider']\n",
    "    paths = record['Collider_Paths']\n",
    "    print(f\"Collider: {confounder['name']}\")\n",
    "    print(\"Paths involved:\")\n",
    "    for path in paths:\n",
    "        print(f\"{path[0]['name']} -> {path[1]['name']}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_structural_equations(G, df):\n",
    "    equations = {}\n",
    "\n",
    "    for node in G.nodes:\n",
    "        parents = list(G.predecessors(node))  # Get parent nodes (causes)\n",
    "        \n",
    "        if parents:  # Only fit a model if the node has causes\n",
    "            X = df[parents]\n",
    "            y = df[node]\n",
    "\n",
    "            # Fit a linear regression model\n",
    "            model = LinearRegression().fit(X, y)\n",
    "            coeffs = model.coef_\n",
    "            intercept = model.intercept_\n",
    "\n",
    "            # Construct equation as a string\n",
    "            equation = f\"{node} = {intercept:.3f} \"\n",
    "            for i, parent in enumerate(parents):\n",
    "                equation += f\"+ ({coeffs[i]:.3f} * {parent}) \"\n",
    "\n",
    "            equations[node] = {}\n",
    "            \n",
    "            equations[node]['equation'] = equation.strip()\n",
    "            equations[node]['intercept'] = intercept\n",
    "            equations[node]['coefficients'] = coeffs\n",
    "            equations[node]['parents'] = parents\n",
    "             \n",
    "    return equations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equation for y: {'equation': 'y = 7425467.850 + (-2745095.676 * W0) + (740510.748 * W1) + (-2089585.355 * W2) + (4145033.822 * W3) + (-1523192.425 * W4) + (-147399.552 * FD0) + (400362.308 * FD1) + (-144406.464 * FD2) + (-169550.125 * FD3) + (820.632 * FD4) + (2941946.068 * X0) + (3337124.613 * X1) + (4500421.754 * X2) + (1386938.415 * X3) + (2286167.948 * X4)', 'intercept': np.float64(7425467.8500168715), 'coefficients': array([-2.74509568e+06,  7.40510748e+05, -2.08958535e+06,  4.14503382e+06,\n",
      "       -1.52319242e+06, -1.47399552e+05,  4.00362308e+05, -1.44406464e+05,\n",
      "       -1.69550125e+05,  8.20631511e+02,  2.94194607e+06,  3.33712461e+06,\n",
      "        4.50042175e+06,  1.38693841e+06,  2.28616795e+06]), 'parents': ['W0', 'W1', 'W2', 'W3', 'W4', 'FD0', 'FD1', 'FD2', 'FD3', 'FD4', 'X0', 'X1', 'X2', 'X3', 'X4']}\n",
      "Equation for FD0: {'equation': 'FD0 = 0.060 + (0.205 * W0) + (-0.089 * W1) + (0.399 * W2) + (-0.106 * W3) + (0.452 * W4) + (2.487 * v0) + (1.834 * v1) + (1.734 * v2) + (4.069 * v3) + (1.542 * v4)', 'intercept': np.float64(0.05957539840656523), 'coefficients': array([ 0.20462138, -0.08880935,  0.39880446, -0.10620228,  0.4518565 ,\n",
      "        2.48688512,  1.83380178,  1.73413157,  4.06854646,  1.54170963]), 'parents': ['W0', 'W1', 'W2', 'W3', 'W4', 'v0', 'v1', 'v2', 'v3', 'v4']}\n",
      "Equation for FD1: {'equation': 'FD1 = 0.071 + (0.127 * W0) + (0.201 * W1) + (0.219 * W2) + (0.799 * W3) + (0.456 * W4) + (1.074 * v0) + (3.934 * v1) + (2.273 * v2) + (0.343 * v3) + (3.834 * v4)', 'intercept': np.float64(0.07095446044655773), 'coefficients': array([0.1274841 , 0.2009638 , 0.21924331, 0.79866136, 0.45551625,\n",
      "       1.07427212, 3.93442337, 2.27296996, 0.34329156, 3.83423575]), 'parents': ['W0', 'W1', 'W2', 'W3', 'W4', 'v0', 'v1', 'v2', 'v3', 'v4']}\n",
      "Equation for FD2: {'equation': 'FD2 = 0.110 + (0.519 * W0) + (0.115 * W1) + (0.430 * W2) + (0.102 * W3) + (0.338 * W4) + (2.077 * v0) + (1.114 * v1) + (2.709 * v2) + (1.785 * v3) + (1.292 * v4)', 'intercept': np.float64(0.11007235203870636), 'coefficients': array([0.5192275 , 0.11489869, 0.43004116, 0.10150951, 0.33752868,\n",
      "       2.07683633, 1.11353945, 2.709088  , 1.78492651, 1.29172406]), 'parents': ['W0', 'W1', 'W2', 'W3', 'W4', 'v0', 'v1', 'v2', 'v3', 'v4']}\n",
      "Equation for FD3: {'equation': 'FD3 = 0.009 + (0.374 * W0) + (0.017 * W1) + (0.282 * W2) + (0.523 * W3) + (0.271 * W4) + (4.880 * v0) + (4.483 * v1) + (0.786 * v2) + (0.727 * v3) + (4.892 * v4)', 'intercept': np.float64(0.008529546889448625), 'coefficients': array([0.37385327, 0.0171275 , 0.28216918, 0.52336569, 0.27139695,\n",
      "       4.88031906, 4.48274088, 0.78624053, 0.72676957, 4.89240224]), 'parents': ['W0', 'W1', 'W2', 'W3', 'W4', 'v0', 'v1', 'v2', 'v3', 'v4']}\n",
      "Equation for FD4: {'equation': 'FD4 = 0.044 + (0.332 * W0) + (0.578 * W1) + (0.345 * W2) + (0.358 * W3) + (0.177 * W4) + (0.707 * v0) + (3.280 * v1) + (4.361 * v2) + (0.701 * v3) + (4.480 * v4)', 'intercept': np.float64(0.04415917561861704), 'coefficients': array([0.33242028, 0.57825274, 0.34532693, 0.35842064, 0.17655991,\n",
      "       0.70748538, 3.28043393, 4.36104684, 0.70128241, 4.47983288]), 'parents': ['W0', 'W1', 'W2', 'W3', 'W4', 'v0', 'v1', 'v2', 'v3', 'v4']}\n",
      "Equation for v0: {'equation': 'v0 = -0.123 + (0.051 * W0) + (3.689 * W1) + (1.245 * W2) + (4.923 * W3) + (2.826 * W4) + (11.231 * Z0) + (11.128 * Z1)', 'intercept': np.float64(-0.12267220770124876), 'coefficients': array([ 0.05113991,  3.68947209,  1.24538711,  4.92347651,  2.82605459,\n",
      "       11.23112489, 11.12821352]), 'parents': ['W0', 'W1', 'W2', 'W3', 'W4', 'Z0', 'Z1']}\n",
      "Equation for v1: {'equation': 'v1 = -0.060 + (3.590 * W0) + (1.438 * W1) + (1.345 * W2) + (0.114 * W3) + (1.383 * W4) + (10.870 * Z0) + (11.569 * Z1)', 'intercept': np.float64(-0.05950917566399738), 'coefficients': array([ 3.59042034,  1.4380458 ,  1.3446277 ,  0.11350194,  1.38311737,\n",
      "       10.87048049, 11.56926011]), 'parents': ['W0', 'W1', 'W2', 'W3', 'W4', 'Z0', 'Z1']}\n",
      "Equation for v2: {'equation': 'v2 = -0.046 + (1.202 * W0) + (5.052 * W1) + (1.406 * W2) + (0.378 * W3) + (4.476 * W4) + (11.133 * Z0) + (10.724 * Z1)', 'intercept': np.float64(-0.04618699844214014), 'coefficients': array([ 1.20158389,  5.05170356,  1.40571163,  0.37767233,  4.4757639 ,\n",
      "       11.13344088, 10.72429704]), 'parents': ['W0', 'W1', 'W2', 'W3', 'W4', 'Z0', 'Z1']}\n",
      "Equation for v3: {'equation': 'v3 = 0.015 + (1.631 * W0) + (4.458 * W1) + (1.433 * W2) + (2.477 * W3) + (3.384 * W4) + (10.923 * Z0) + (11.034 * Z1)', 'intercept': np.float64(0.01463195573939835), 'coefficients': array([ 1.63128296,  4.45770916,  1.43316626,  2.47651928,  3.38390741,\n",
      "       10.9233874 , 11.03422176]), 'parents': ['W0', 'W1', 'W2', 'W3', 'W4', 'Z0', 'Z1']}\n",
      "Equation for v4: {'equation': 'v4 = -0.038 + (1.079 * W0) + (3.949 * W1) + (2.360 * W2) + (2.029 * W3) + (4.954 * W4) + (10.547 * Z0) + (10.977 * Z1)', 'intercept': np.float64(-0.03752183229228745), 'coefficients': array([ 1.07927042,  3.94913711,  2.36045404,  2.02855683,  4.9535576 ,\n",
      "       10.54707842, 10.97731264]), 'parents': ['W0', 'W1', 'W2', 'W3', 'W4', 'Z0', 'Z1']}\n"
     ]
    }
   ],
   "source": [
    "equations = estimate_structural_equations(model, df)\n",
    "\n",
    "# Print all structural equations\n",
    "for node, equation in equations.items():\n",
    "    print(f\"Equation for {node}: {equation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_structural_equations(equations):\n",
    "    cypher_statements = []\n",
    "    for node, equation in equations.items():\n",
    "        for idx,parent in enumerate(equation['parents']):\n",
    "            cypher_statements.append(f\"MATCH (cv1:CausalVariable {{name: '{parent}'}})-[r:CAUSALLY_LINKED]->(cv2:CausalVariable {{name: '{node}'}}) SET r.parameter = {equation['coefficients'][idx]};\")\n",
    "    for node, equation in equations.items():\n",
    "        cypher_statements.append(f\"MATCH (cv1:CausalVariable {{name: '{node}'}}) SET cv1.intercept = {equation['intercept']};\")\n",
    "    # Save to a file\n",
    "    with open(\"structural_equations.cypher\", \"w\") as f:\n",
    "        f.write(\"\\n\".join(cypher_statements))\n",
    "        \n",
    "    try:\n",
    "        os.system('/Users/amedeo/Downloads/neo4j-community-5.12.0/bin/cypher-shell -u neo4j -p neo4j -f ./structural_equations.cypher')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    print(\"Cypher export completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cypher export completed!\n"
     ]
    }
   ],
   "source": [
    "set_structural_equations(equations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_intervention(target_variabel, value,neo4jConnector, output_variabel):\n",
    "    \n",
    "    neo4jConnector.merge_query(f\"MATCH (a:{target_variabel}) SET a.old_value=a.value, a.value= {value};\")\n",
    "    \n",
    "    intervention_distribution = neo4jConnector.query(f\"MATCH (b)-[:BELONGS]->(cv:CausalVariable {{name:'{output_variabel}'}})<-[r:CAUSALLY_LINKED]-(parent:CausalVariable)<-[:BELONGS]-(a)-->(b) WITH distinct b, cv, SUM(r.parameter * a.value) AS sum_a RETURN b, sum_a + cv.intercept AS adjustedSum\")\n",
    "    \n",
    "    neo4jConnector.merge_query(f\"MATCH (a:{target_variabel}) SET a.value= a.old_value;\")\n",
    "    \n",
    "    return intervention_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12688112258911133\n",
      "-139336974.35297316\n",
      "114143306.87011951\n"
     ]
    }
   ],
   "source": [
    "t0=time.time()\n",
    "intervention_distribution = do_intervention('W0', 0.5, neo4jConnector, 'y')\n",
    "t1=time.time()\n",
    "print(t1-t0)\n",
    "post_intervention_values = []\n",
    "\n",
    "for id in intervention_distribution:\n",
    "    post_intervention_values.append(id['adjustedSum'])\n",
    "    \n",
    "print(np.mean(post_intervention_values))\n",
    "print(np.std(post_intervention_values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_counterfactual(target_instance, target_variabel, value,neo4jConnector,output_variabel):\n",
    "    \n",
    "    neo4jConnector.merge_query(f\"MATCH (a:{target_variabel}) SET a.old_value=a.value, a.value= {value};\")\n",
    "    \n",
    "    intervention_distribution = neo4jConnector.query(f\"MATCH (b:{output_variabel} {{id:'{target_instance}'}})-[:BELONGS]->(cv:CausalVariable {{name:'{output_variabel}'}}) MATCH (cv)<-[r:CAUSALLY_LINKED]-(parent:CausalVariable)<-[:BELONGS]-(a)-->(b) WITH distinct b, cv, SUM(r.parameter * a.value) AS sum_a RETURN b, sum_a + cv.intercept AS adjustedSum\")\n",
    "    \n",
    "    neo4jConnector.merge_query(f\"MATCH (a:{target_variabel}) SET a.value= a.old_value;\")\n",
    "    \n",
    "    return intervention_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.037010908126831055\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "counterfactual = do_counterfactual('y_1','W0', 0.5, neo4jConnector, 'y')\n",
    "t1 = time.time()\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'b': <Node element_id='4:d5297e9e-0b37-4e68-ab6e-014fbdbed984:295892' labels=frozenset({'y'}) properties={'id': 'y_1', 'value': 19939.848084971505}>,\n",
       "  'adjustedSum': -52374055.358440384}]"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counterfactual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "config1 = {\n",
    "            'num_common_causes':1, \n",
    "            'num_instruments':1, \n",
    "            'num_effect_modifiers':1,\n",
    "            'num_treatments':1,\n",
    "            'num_frontdoor_variables':1,\n",
    "            }\n",
    "num_samples = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n"
     ]
    }
   ],
   "source": [
    "merge_times = []\n",
    "mediator_times = []\n",
    "strict_confounder_times = []\n",
    "confounder_times = []\n",
    "collider_times = []\n",
    "intervention_times = []\n",
    "counterfactual_times = []\n",
    "neo4jConnector.clearNeo4j()\n",
    "data = generate_data(num_samples, config1)\n",
    "dag = data[\"gml_graph\"]  # Get DAG in GML format\n",
    "model = nx.parse_gml(dag)  # Parse GML to networkx graph\n",
    "df = data[\"df\"]\n",
    "\n",
    "dag_to_neo4j(model)\n",
    "data_to_neo4j(df, model)\n",
    "\n",
    "equations = estimate_structural_equations(model, df)\n",
    "set_structural_equations(equations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mediators = mediator_analysis(neo4jConnector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Mediator': <Node element_id='4:d5297e9e-0b37-4e68-ab6e-014fbdbed984:310178' labels=frozenset({'CausalVariable'}) properties={'intercept': 0.009206882180876619, 'name': 'FD0'}>,\n",
       "  'Paths_Involved': [[<Node element_id='4:d5297e9e-0b37-4e68-ab6e-014fbdbed984:310179' labels=frozenset({'CausalVariable'}) properties={'intercept': 0.021373439232440283, 'name': 'v0'}>,\n",
       "    <Node element_id='4:d5297e9e-0b37-4e68-ab6e-014fbdbed984:310175' labels=frozenset({'CausalVariable'}) properties={'intercept': 10.30653343833064, 'name': 'y'}>]]},\n",
       " {'Mediator': <Node element_id='4:d5297e9e-0b37-4e68-ab6e-014fbdbed984:310179' labels=frozenset({'CausalVariable'}) properties={'intercept': 0.021373439232440283, 'name': 'v0'}>,\n",
       "  'Paths_Involved': [[<Node element_id='4:d5297e9e-0b37-4e68-ab6e-014fbdbed984:310177' labels=frozenset({'CausalVariable'}) properties={'name': 'Z0'}>,\n",
       "    <Node element_id='4:d5297e9e-0b37-4e68-ab6e-014fbdbed984:310178' labels=frozenset({'CausalVariable'}) properties={'intercept': 0.009206882180876619, 'name': 'FD0'}>]]}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mediators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Number of samples: 1000\n",
      "Merge times: 1.0085125207901\n",
      "Mediator times: 0.024452996253967286\n",
      "Strict confounder times: 0.020829105377197267\n",
      "Confounder times: 0.0026035547256469727\n",
      "Collider times: 0.006811380386352539\n",
      "Intervention times: 0.121703839302063\n",
      "Counterfactual times: 0.033784341812133786\n"
     ]
    }
   ],
   "source": [
    " \n",
    "\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    t0 = time.time()\n",
    "    materialize_views_from_data(model)\n",
    "    t1 = time.time()\n",
    "    \n",
    "    merge_times.append(t1-t0)\n",
    "    \n",
    "    \n",
    "    t0 = time.time()\n",
    "    mediators = mediator_analysis(neo4jConnector)\n",
    "    t1 = time.time()\n",
    "    \n",
    "    mediator_times.append(t1-t0)\n",
    "            \n",
    "    t0 = time.time()\n",
    "    confounders_not_mediators = strict_confounders_analysis(neo4jConnector)\n",
    "    t1 = time.time()\n",
    "    strict_confounder_times.append(t1-t0)\n",
    "            \n",
    "    t0 = time.time()\n",
    "    confounders = strict_confounders_analysis(neo4jConnector)\n",
    "    t1 = time.time()\n",
    "    confounder_times.append(t1-t0)\n",
    "            \n",
    "    t0 = time.time()\n",
    "    confounders = collider_analysis(neo4jConnector)\n",
    "    t1 = time.time()\n",
    "    collider_times.append(t1-t0)\n",
    "\n",
    "    t0=time.time()\n",
    "    intervention_distribution = do_intervention('W0', 0.5, neo4jConnector, 'y')\n",
    "    t1=time.time()\n",
    "    intervention_times.append(t1-t0)\n",
    "\n",
    "    t0 = time.time()\n",
    "    counterfactual = do_counterfactual('y_1','W0', 0.5, neo4jConnector, 'y')\n",
    "    t1 = time.time()\n",
    "    counterfactual_times.append(t1-t0)\n",
    "    \n",
    "print(f\"Number of samples: {num_samples}\")\n",
    "print(f\"Merge times: {np.mean(merge_times)}\")\n",
    "print(f\"Mediator times: {np.mean(mediator_times)}\")\n",
    "print(f\"Strict confounder times: {np.mean(strict_confounder_times)}\")\n",
    "print(f\"Confounder times: {np.mean(confounder_times)}\")\n",
    "print(f\"Collider times: {np.mean(collider_times)}\")\n",
    "print(f\"Intervention times: {np.mean(intervention_times)}\")\n",
    "print(f\"Counterfactual times: {np.mean(counterfactual_times)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n"
     ]
    }
   ],
   "source": [
    "merge_times = []\n",
    "mediator_times = []\n",
    "strict_confounder_times = []\n",
    "confounder_times = []\n",
    "collider_times = []\n",
    "intervention_times = []\n",
    "counterfactual_times = []\n",
    "neo4jConnector.clearNeo4j()\n",
    "data = generate_data(num_samples, config1)\n",
    "dag = data[\"gml_graph\"]  # Get DAG in GML format\n",
    "model = nx.parse_gml(dag)  # Parse GML to networkx graph\n",
    "df = data[\"df\"]\n",
    "\n",
    "dag_to_neo4j(model)\n",
    "data_to_neo4j(df, model)\n",
    "\n",
    "equations = estimate_structural_equations(model, df)\n",
    "set_structural_equations(equations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Number of samples: 10000\n",
      "Merge times: 1.1795682907104492\n",
      "Mediator times: 0.012315702438354493\n",
      "Strict confounder times: 0.011739826202392578\n",
      "Confounder times: 0.003736138343811035\n",
      "Collider times: 0.005746197700500488\n",
      "Intervention times: 0.8576841115951538\n",
      "Counterfactual times: 0.05885138511657715\n"
     ]
    }
   ],
   "source": [
    " \n",
    "\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    t0 = time.time()\n",
    "    materialize_views_from_data(model)\n",
    "    t1 = time.time()\n",
    "    \n",
    "    merge_times.append(t1-t0)\n",
    "    \n",
    "    \n",
    "    t0 = time.time()\n",
    "    mediators = mediator_analysis(neo4jConnector)\n",
    "    t1 = time.time()\n",
    "    \n",
    "    mediator_times.append(t1-t0)\n",
    "            \n",
    "    t0 = time.time()\n",
    "    confounders_not_mediators = strict_confounders_analysis(neo4jConnector)\n",
    "    t1 = time.time()\n",
    "    strict_confounder_times.append(t1-t0)\n",
    "            \n",
    "    t0 = time.time()\n",
    "    confounders = strict_confounders_analysis(neo4jConnector)\n",
    "    t1 = time.time()\n",
    "    confounder_times.append(t1-t0)\n",
    "            \n",
    "    t0 = time.time()\n",
    "    confounders = collider_analysis(neo4jConnector)\n",
    "    t1 = time.time()\n",
    "    collider_times.append(t1-t0)\n",
    "\n",
    "    t0=time.time()\n",
    "    intervention_distribution = do_intervention('W0', 0.5, neo4jConnector, 'y')\n",
    "    t1=time.time()\n",
    "    intervention_times.append(t1-t0)\n",
    "\n",
    "    t0 = time.time()\n",
    "    counterfactual = do_counterfactual('y_1','W0', 0.5, neo4jConnector, 'y')\n",
    "    t1 = time.time()\n",
    "    counterfactual_times.append(t1-t0)\n",
    "    \n",
    "print(f\"Number of samples: {num_samples}\")\n",
    "print(f\"Merge times: {np.mean(merge_times)}\")\n",
    "print(f\"Mediator times: {np.mean(mediator_times)}\")\n",
    "print(f\"Strict confounder times: {np.mean(strict_confounder_times)}\")\n",
    "print(f\"Confounder times: {np.mean(confounder_times)}\")\n",
    "print(f\"Collider times: {np.mean(collider_times)}\")\n",
    "print(f\"Intervention times: {np.mean(intervention_times)}\")\n",
    "print(f\"Counterfactual times: {np.mean(counterfactual_times)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n"
     ]
    }
   ],
   "source": [
    "merge_times = []\n",
    "mediator_times = []\n",
    "strict_confounder_times = []\n",
    "confounder_times = []\n",
    "collider_times = []\n",
    "intervention_times = []\n",
    "counterfactual_times = []\n",
    "neo4jConnector.clearNeo4j()\n",
    "data = generate_data(num_samples, config1)*\n",
    "dag = data[\"gml_graph\"]  # Get DAG in GML format\n",
    "model = nx.parse_gml(dag)  # Parse GML to networkx graph\n",
    "df = data[\"df\"]\n",
    "\n",
    "dag_to_neo4j(model)\n",
    "data_to_neo4j(df, model)\n",
    "\n",
    "equations = estimate_structural_equations(model, df)\n",
    "set_structural_equations(equations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Number of samples: 100000\n",
      "Merge times: 3.9701653718948364\n",
      "Mediator times: 0.008602595329284668\n",
      "Strict confounder times: 0.007948613166809082\n",
      "Confounder times: 0.0027294397354125977\n",
      "Collider times: 0.003624367713928223\n",
      "Intervention times: 10.033546209335327\n",
      "Counterfactual times: 0.9108143806457519\n"
     ]
    }
   ],
   "source": [
    " \n",
    "\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    t0 = time.time()\n",
    "    materialize_views_from_data(model)\n",
    "    t1 = time.time()\n",
    "    \n",
    "    merge_times.append(t1-t0)\n",
    "    \n",
    "    \n",
    "    t0 = time.time()\n",
    "    mediators = mediator_analysis(neo4jConnector)\n",
    "    t1 = time.time()\n",
    "    \n",
    "    mediator_times.append(t1-t0)\n",
    "            \n",
    "    t0 = time.time()\n",
    "    confounders_not_mediators = strict_confounders_analysis(neo4jConnector)\n",
    "    t1 = time.time()\n",
    "    strict_confounder_times.append(t1-t0)\n",
    "            \n",
    "    t0 = time.time()\n",
    "    confounders = strict_confounders_analysis(neo4jConnector)\n",
    "    t1 = time.time()\n",
    "    confounder_times.append(t1-t0)\n",
    "            \n",
    "    t0 = time.time()\n",
    "    confounders = collider_analysis(neo4jConnector)\n",
    "    t1 = time.time()\n",
    "    collider_times.append(t1-t0)\n",
    "\n",
    "    t0=time.time()\n",
    "    intervention_distribution = do_intervention('W0', 0.5, neo4jConnector, 'y')\n",
    "    t1=time.time()\n",
    "    intervention_times.append(t1-t0)\n",
    "\n",
    "    t0 = time.time()\n",
    "    counterfactual = do_counterfactual('y_1','W0', 0.5, neo4jConnector, 'y')\n",
    "    t1 = time.time()\n",
    "    counterfactual_times.append(t1-t0)\n",
    "    \n",
    "print(f\"Number of samples: {num_samples}\")\n",
    "print(f\"Merge times: {np.mean(merge_times)}\")\n",
    "print(f\"Mediator times: {np.mean(mediator_times)}\")\n",
    "print(f\"Strict confounder times: {np.mean(strict_confounder_times)}\")\n",
    "print(f\"Confounder times: {np.mean(confounder_times)}\")\n",
    "print(f\"Collider times: {np.mean(collider_times)}\")\n",
    "print(f\"Intervention times: {np.mean(intervention_times)}\")\n",
    "print(f\"Counterfactual times: {np.mean(counterfactual_times)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mediator times: 1.1920271570032293\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "ntervention_distribution = do_intervention('W0', 0.5, neo4jConnector, 'y')\n",
    "t1 = time.time()\n",
    "\n",
    "mediator_times.append(t1-t0)\n",
    "print(f\"Mediator times: {np.mean(mediator_times)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "config3 = {\n",
    "            'num_common_causes':10, \n",
    "            'num_instruments':2, \n",
    "            'num_effect_modifiers':10,\n",
    "            'num_treatments':18,\n",
    "            'num_frontdoor_variables':10,\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n"
     ]
    }
   ],
   "source": [
    "merge_times = []\n",
    "mediator_times = []\n",
    "strict_confounder_times = []\n",
    "confounder_times = []\n",
    "collider_times = []\n",
    "intervention_times = []\n",
    "counterfactual_times = []\n",
    "neo4jConnector.clearNeo4j()\n",
    "data = generate_data(num_samples, config1)\n",
    "dag = data[\"gml_graph\"]  # Get DAG in GML format\n",
    "model = nx.parse_gml(dag)  # Parse GML to networkx graph\n",
    "df = data[\"df\"]\n",
    "\n",
    "dag_to_neo4j(model)\n",
    "data_to_neo4j(df, model)\n",
    "\n",
    "equations = estimate_structural_equations(model, df)\n",
    "set_structural_equations(equations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Number of samples: 1000\n",
      "Merge times: 1.0288001537322997\n",
      "Mediator times: 0.0075377941131591795\n",
      "Strict confounder times: 0.007444953918457032\n",
      "Confounder times: 0.0018110990524291993\n",
      "Collider times: 0.0036610126495361327\n",
      "Intervention times: 0.10612542629241943\n",
      "Counterfactual times: 0.02019820213317871\n"
     ]
    }
   ],
   "source": [
    " \n",
    "\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    t0 = time.time()\n",
    "    materialize_views_from_data(model)\n",
    "    t1 = time.time()\n",
    "    \n",
    "    merge_times.append(t1-t0)\n",
    "    \n",
    "    \n",
    "    t0 = time.time()\n",
    "    mediators = mediator_analysis(neo4jConnector)\n",
    "    t1 = time.time()\n",
    "    \n",
    "    mediator_times.append(t1-t0)\n",
    "            \n",
    "    t0 = time.time()\n",
    "    confounders_not_mediators = strict_confounders_analysis(neo4jConnector)\n",
    "    t1 = time.time()\n",
    "    strict_confounder_times.append(t1-t0)\n",
    "            \n",
    "    t0 = time.time()\n",
    "    confounders = strict_confounders_analysis(neo4jConnector)\n",
    "    t1 = time.time()\n",
    "    confounder_times.append(t1-t0)\n",
    "            \n",
    "    t0 = time.time()\n",
    "    confounders = collider_analysis(neo4jConnector)\n",
    "    t1 = time.time()\n",
    "    collider_times.append(t1-t0)\n",
    "\n",
    "    t0=time.time()\n",
    "    intervention_distribution = do_intervention('W0', 0.5, neo4jConnector, 'y')\n",
    "    t1=time.time()\n",
    "    intervention_times.append(t1-t0)\n",
    "\n",
    "    t0 = time.time()\n",
    "    counterfactual = do_counterfactual('y_1','W0', 0.5, neo4jConnector, 'y')\n",
    "    t1 = time.time()\n",
    "    counterfactual_times.append(t1-t0)\n",
    "    \n",
    "print(f\"Number of samples: {num_samples}\")\n",
    "print(f\"Merge times: {np.mean(merge_times)}\")\n",
    "print(f\"Mediator times: {np.mean(mediator_times)}\")\n",
    "print(f\"Strict confounder times: {np.mean(strict_confounder_times)}\")\n",
    "print(f\"Confounder times: {np.mean(confounder_times)}\")\n",
    "print(f\"Collider times: {np.mean(collider_times)}\")\n",
    "print(f\"Intervention times: {np.mean(intervention_times)}\")\n",
    "print(f\"Counterfactual times: {np.mean(counterfactual_times)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n"
     ]
    }
   ],
   "source": [
    "merge_times = []\n",
    "mediator_times = []\n",
    "strict_confounder_times = []\n",
    "confounder_times = []\n",
    "collider_times = []\n",
    "intervention_times = []\n",
    "counterfactual_times = []\n",
    "neo4jConnector.clearNeo4j()\n",
    "data = generate_data(num_samples, config1)\n",
    "dag = data[\"gml_graph\"]  # Get DAG in GML format\n",
    "model = nx.parse_gml(dag)  # Parse GML to networkx graph\n",
    "df = data[\"df\"]\n",
    "\n",
    "dag_to_neo4j(model)\n",
    "data_to_neo4j(df, model)\n",
    "\n",
    "equations = estimate_structural_equations(model, df)\n",
    "set_structural_equations(equations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Number of samples: 10000\n",
      "Merge times: 1.20693359375\n",
      "Mediator times: 0.006110072135925293\n",
      "Strict confounder times: 0.00545353889465332\n",
      "Confounder times: 0.0015691757202148438\n",
      "Collider times: 0.002817106246948242\n",
      "Intervention times: 0.834347128868103\n",
      "Counterfactual times: 0.052653384208679196\n"
     ]
    }
   ],
   "source": [
    " \n",
    "\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    t0 = time.time()\n",
    "    materialize_views_from_data(model)\n",
    "    t1 = time.time()\n",
    "    \n",
    "    merge_times.append(t1-t0)\n",
    "    \n",
    "    \n",
    "    t0 = time.time()\n",
    "    mediators = mediator_analysis(neo4jConnector)\n",
    "    t1 = time.time()\n",
    "    \n",
    "    mediator_times.append(t1-t0)\n",
    "            \n",
    "    t0 = time.time()\n",
    "    confounders_not_mediators = strict_confounders_analysis(neo4jConnector)\n",
    "    t1 = time.time()\n",
    "    strict_confounder_times.append(t1-t0)\n",
    "            \n",
    "    t0 = time.time()\n",
    "    confounders = strict_confounders_analysis(neo4jConnector)\n",
    "    t1 = time.time()\n",
    "    confounder_times.append(t1-t0)\n",
    "            \n",
    "    t0 = time.time()\n",
    "    confounders = collider_analysis(neo4jConnector)\n",
    "    t1 = time.time()\n",
    "    collider_times.append(t1-t0)\n",
    "\n",
    "    t0=time.time()\n",
    "    intervention_distribution = do_intervention('W0', 0.5, neo4jConnector, 'y')\n",
    "    t1=time.time()\n",
    "    intervention_times.append(t1-t0)\n",
    "\n",
    "    t0 = time.time()\n",
    "    counterfactual = do_counterfactual('y_1','W0', 0.5, neo4jConnector, 'y')\n",
    "    t1 = time.time()\n",
    "    counterfactual_times.append(t1-t0)\n",
    "    \n",
    "print(f\"Number of samples: {num_samples}\")\n",
    "print(f\"Merge times: {np.mean(merge_times)}\")\n",
    "print(f\"Mediator times: {np.mean(mediator_times)}\")\n",
    "print(f\"Strict confounder times: {np.mean(strict_confounder_times)}\")\n",
    "print(f\"Confounder times: {np.mean(confounder_times)}\")\n",
    "print(f\"Collider times: {np.mean(collider_times)}\")\n",
    "print(f\"Intervention times: {np.mean(intervention_times)}\")\n",
    "print(f\"Counterfactual times: {np.mean(counterfactual_times)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n"
     ]
    }
   ],
   "source": [
    "merge_times = []\n",
    "mediator_times = []\n",
    "strict_confounder_times = []\n",
    "confounder_times = []\n",
    "collider_times = []\n",
    "intervention_times = []\n",
    "counterfactual_times = []\n",
    "neo4jConnector.clearNeo4j()\n",
    "data = generate_data(num_samples, config1)\n",
    "dag = data[\"gml_graph\"]  # Get DAG in GML format\n",
    "model = nx.parse_gml(dag)  # Parse GML to networkx graph\n",
    "df = data[\"df\"]\n",
    "\n",
    "dag_to_neo4j(model)\n",
    "data_to_neo4j(df, model)\n",
    "\n",
    "equations = estimate_structural_equations(model, df)\n",
    "set_structural_equations(equations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Number of samples: 100000\n",
      "Merge times: 3.9890846729278566\n",
      "Mediator times: 0.007110857963562011\n",
      "Strict confounder times: 0.004676198959350586\n",
      "Confounder times: 0.002042555809020996\n",
      "Collider times: 0.0036124706268310545\n",
      "Intervention times: 9.830963897705079\n",
      "Counterfactual times: 0.8922810554504395\n"
     ]
    }
   ],
   "source": [
    " \n",
    "\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    t0 = time.time()\n",
    "    materialize_views_from_data(model)\n",
    "    t1 = time.time()\n",
    "    \n",
    "    merge_times.append(t1-t0)\n",
    "    \n",
    "    \n",
    "    t0 = time.time()\n",
    "    mediators = mediator_analysis(neo4jConnector)\n",
    "    t1 = time.time()\n",
    "    \n",
    "    mediator_times.append(t1-t0)\n",
    "            \n",
    "    t0 = time.time()\n",
    "    confounders_not_mediators = strict_confounders_analysis(neo4jConnector)\n",
    "    t1 = time.time()\n",
    "    strict_confounder_times.append(t1-t0)\n",
    "            \n",
    "    t0 = time.time()\n",
    "    confounders = strict_confounders_analysis(neo4jConnector)\n",
    "    t1 = time.time()\n",
    "    confounder_times.append(t1-t0)\n",
    "            \n",
    "    t0 = time.time()\n",
    "    confounders = collider_analysis(neo4jConnector)\n",
    "    t1 = time.time()\n",
    "    collider_times.append(t1-t0)\n",
    "\n",
    "    t0=time.time()\n",
    "    intervention_distribution = do_intervention('W0', 0.5, neo4jConnector, 'y')\n",
    "    t1=time.time()\n",
    "    intervention_times.append(t1-t0)\n",
    "\n",
    "    t0 = time.time()\n",
    "    counterfactual = do_counterfactual('y_1','W0', 0.5, neo4jConnector, 'y')\n",
    "    t1 = time.time()\n",
    "    counterfactual_times.append(t1-t0)\n",
    "    \n",
    "print(f\"Number of samples: {num_samples}\")\n",
    "print(f\"Merge times: {np.mean(merge_times)}\")\n",
    "print(f\"Mediator times: {np.mean(mediator_times)}\")\n",
    "print(f\"Strict confounder times: {np.mean(strict_confounder_times)}\")\n",
    "print(f\"Confounder times: {np.mean(confounder_times)}\")\n",
    "print(f\"Collider times: {np.mean(collider_times)}\")\n",
    "print(f\"Intervention times: {np.mean(intervention_times)}\")\n",
    "print(f\"Counterfactual times: {np.mean(counterfactual_times)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "config2 = {\n",
    "            'num_common_causes':5, \n",
    "            'num_instruments':2, \n",
    "            'num_effect_modifiers':5,\n",
    "            'num_treatments':8,\n",
    "            'num_frontdoor_variables':5,\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n"
     ]
    }
   ],
   "source": [
    "merge_times = []\n",
    "mediator_times = []\n",
    "strict_confounder_times = []\n",
    "confounder_times = []\n",
    "collider_times = []\n",
    "intervention_times = []\n",
    "counterfactual_times = []\n",
    "neo4jConnector.clearNeo4j()\n",
    "data = generate_data(num_samples, config1)\n",
    "dag = data[\"gml_graph\"]  # Get DAG in GML format\n",
    "model = nx.parse_gml(dag)  # Parse GML to networkx graph\n",
    "df = data[\"df\"]\n",
    "\n",
    "dag_to_neo4j(model)\n",
    "data_to_neo4j(df, model)\n",
    "\n",
    "equations = estimate_structural_equations(model, df)\n",
    "set_structural_equations(equations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Number of samples: 1000\n",
      "Merge times: 1.0320783853530884\n",
      "Mediator times: 0.009514141082763671\n",
      "Strict confounder times: 0.007951617240905762\n",
      "Confounder times: 0.0020543813705444338\n",
      "Collider times: 0.0041799783706665036\n",
      "Intervention times: 0.10910227298736572\n",
      "Counterfactual times: 0.02249436378479004\n"
     ]
    }
   ],
   "source": [
    " \n",
    "\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    t0 = time.time()\n",
    "    materialize_views_from_data(model)\n",
    "    t1 = time.time()\n",
    "    \n",
    "    merge_times.append(t1-t0)\n",
    "    \n",
    "    \n",
    "    t0 = time.time()\n",
    "    mediators = mediator_analysis(neo4jConnector)\n",
    "    t1 = time.time()\n",
    "    \n",
    "    mediator_times.append(t1-t0)\n",
    "            \n",
    "    t0 = time.time()\n",
    "    confounders_not_mediators = strict_confounders_analysis(neo4jConnector)\n",
    "    t1 = time.time()\n",
    "    strict_confounder_times.append(t1-t0)\n",
    "            \n",
    "    t0 = time.time()\n",
    "    confounders = strict_confounders_analysis(neo4jConnector)\n",
    "    t1 = time.time()\n",
    "    confounder_times.append(t1-t0)\n",
    "            \n",
    "    t0 = time.time()\n",
    "    confounders = collider_analysis(neo4jConnector)\n",
    "    t1 = time.time()\n",
    "    collider_times.append(t1-t0)\n",
    "\n",
    "    t0=time.time()\n",
    "    intervention_distribution = do_intervention('W0', 0.5, neo4jConnector, 'y')\n",
    "    t1=time.time()\n",
    "    intervention_times.append(t1-t0)\n",
    "\n",
    "    t0 = time.time()\n",
    "    counterfactual = do_counterfactual('y_1','W0', 0.5, neo4jConnector, 'y')\n",
    "    t1 = time.time()\n",
    "    counterfactual_times.append(t1-t0)\n",
    "    \n",
    "print(f\"Number of samples: {num_samples}\")\n",
    "print(f\"Merge times: {np.mean(merge_times)}\")\n",
    "print(f\"Mediator times: {np.mean(mediator_times)}\")\n",
    "print(f\"Strict confounder times: {np.mean(strict_confounder_times)}\")\n",
    "print(f\"Confounder times: {np.mean(confounder_times)}\")\n",
    "print(f\"Collider times: {np.mean(collider_times)}\")\n",
    "print(f\"Intervention times: {np.mean(intervention_times)}\")\n",
    "print(f\"Counterfactual times: {np.mean(counterfactual_times)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n"
     ]
    }
   ],
   "source": [
    "merge_times = []\n",
    "mediator_times = []\n",
    "strict_confounder_times = []\n",
    "confounder_times = []\n",
    "collider_times = []\n",
    "intervention_times = []\n",
    "counterfactual_times = []\n",
    "neo4jConnector.clearNeo4j()\n",
    "data = generate_data(num_samples, config1)\n",
    "dag = data[\"gml_graph\"]  # Get DAG in GML format\n",
    "model = nx.parse_gml(dag)  # Parse GML to networkx graph\n",
    "df = data[\"df\"]\n",
    "\n",
    "dag_to_neo4j(model)\n",
    "data_to_neo4j(df, model)\n",
    "\n",
    "equations = estimate_structural_equations(model, df)\n",
    "set_structural_equations(equations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Number of samples: 10000\n",
      "Merge times: 1.276483702659607\n",
      "Mediator times: 0.009201359748840333\n",
      "Strict confounder times: 0.008504080772399902\n",
      "Confounder times: 0.0022101640701293946\n",
      "Collider times: 0.01230635643005371\n",
      "Intervention times: 0.8381062030792237\n",
      "Counterfactual times: 0.05692293643951416\n"
     ]
    }
   ],
   "source": [
    " \n",
    "\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    t0 = time.time()\n",
    "    materialize_views_from_data(model)\n",
    "    t1 = time.time()\n",
    "    \n",
    "    merge_times.append(t1-t0)\n",
    "    \n",
    "    \n",
    "    t0 = time.time()\n",
    "    mediators = mediator_analysis(neo4jConnector)\n",
    "    t1 = time.time()\n",
    "    \n",
    "    mediator_times.append(t1-t0)\n",
    "            \n",
    "    t0 = time.time()\n",
    "    confounders_not_mediators = strict_confounders_analysis(neo4jConnector)\n",
    "    t1 = time.time()\n",
    "    strict_confounder_times.append(t1-t0)\n",
    "            \n",
    "    t0 = time.time()\n",
    "    confounders = strict_confounders_analysis(neo4jConnector)\n",
    "    t1 = time.time()\n",
    "    confounder_times.append(t1-t0)\n",
    "            \n",
    "    t0 = time.time()\n",
    "    confounders = collider_analysis(neo4jConnector)\n",
    "    t1 = time.time()\n",
    "    collider_times.append(t1-t0)\n",
    "\n",
    "    t0=time.time()\n",
    "    intervention_distribution = do_intervention('W0', 0.5, neo4jConnector, 'y')\n",
    "    t1=time.time()\n",
    "    intervention_times.append(t1-t0)\n",
    "\n",
    "    t0 = time.time()\n",
    "    counterfactual = do_counterfactual('y_1','W0', 0.5, neo4jConnector, 'y')\n",
    "    t1 = time.time()\n",
    "    counterfactual_times.append(t1-t0)\n",
    "    \n",
    "print(f\"Number of samples: {num_samples}\")\n",
    "print(f\"Merge times: {np.mean(merge_times)}\")\n",
    "print(f\"Mediator times: {np.mean(mediator_times)}\")\n",
    "print(f\"Strict confounder times: {np.mean(strict_confounder_times)}\")\n",
    "print(f\"Confounder times: {np.mean(confounder_times)}\")\n",
    "print(f\"Collider times: {np.mean(collider_times)}\")\n",
    "print(f\"Intervention times: {np.mean(intervention_times)}\")\n",
    "print(f\"Counterfactual times: {np.mean(counterfactual_times)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n"
     ]
    }
   ],
   "source": [
    "merge_times = []\n",
    "mediator_times = []\n",
    "strict_confounder_times = []\n",
    "confounder_times = []\n",
    "collider_times = []\n",
    "intervention_times = []\n",
    "counterfactual_times = []\n",
    "neo4jConnector.clearNeo4j()\n",
    "data = generate_data(num_samples, config1)\n",
    "dag = data[\"gml_graph\"]  # Get DAG in GML format\n",
    "model = nx.parse_gml(dag)  # Parse GML to networkx graph\n",
    "df = data[\"df\"]\n",
    "\n",
    "dag_to_neo4j(model)\n",
    "data_to_neo4j(df, model)\n",
    "\n",
    "equations = estimate_structural_equations(model, df)\n",
    "set_structural_equations(equations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Cypher export completed!\n",
      "Number of samples: 100000\n",
      "Merge times: 3.973950147628784\n",
      "Mediator times: 0.011180806159973144\n",
      "Strict confounder times: 0.010750627517700196\n",
      "Confounder times: 0.0027007102966308595\n",
      "Collider times: 0.0035307645797729493\n",
      "Intervention times: 9.951258182525635\n",
      "Counterfactual times: 0.935277271270752\n"
     ]
    }
   ],
   "source": [
    " \n",
    "\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    t0 = time.time()\n",
    "    materialize_views_from_data(model)\n",
    "    t1 = time.time()\n",
    "    \n",
    "    merge_times.append(t1-t0)\n",
    "    \n",
    "    \n",
    "    t0 = time.time()\n",
    "    mediators = mediator_analysis(neo4jConnector)\n",
    "    t1 = time.time()\n",
    "    \n",
    "    mediator_times.append(t1-t0)\n",
    "            \n",
    "    t0 = time.time()\n",
    "    confounders_not_mediators = strict_confounders_analysis(neo4jConnector)\n",
    "    t1 = time.time()\n",
    "    strict_confounder_times.append(t1-t0)\n",
    "            \n",
    "    t0 = time.time()\n",
    "    confounders = strict_confounders_analysis(neo4jConnector)\n",
    "    t1 = time.time()\n",
    "    confounder_times.append(t1-t0)\n",
    "            \n",
    "    t0 = time.time()\n",
    "    confounders = collider_analysis(neo4jConnector)\n",
    "    t1 = time.time()\n",
    "    collider_times.append(t1-t0)\n",
    "\n",
    "    t0=time.time()\n",
    "    intervention_distribution = do_intervention('W0', 0.5, neo4jConnector, 'y')\n",
    "    t1=time.time()\n",
    "    intervention_times.append(t1-t0)\n",
    "\n",
    "    t0 = time.time()\n",
    "    counterfactual = do_counterfactual('y_1','W0', 0.5, neo4jConnector, 'y')\n",
    "    t1 = time.time()\n",
    "    counterfactual_times.append(t1-t0)\n",
    "    \n",
    "print(f\"Number of samples: {num_samples}\")\n",
    "print(f\"Merge times: {np.mean(merge_times)}\")\n",
    "print(f\"Mediator times: {np.mean(mediator_times)}\")\n",
    "print(f\"Strict confounder times: {np.mean(strict_confounder_times)}\")\n",
    "print(f\"Confounder times: {np.mean(confounder_times)}\")\n",
    "print(f\"Collider times: {np.mean(collider_times)}\")\n",
    "print(f\"Intervention times: {np.mean(intervention_times)}\")\n",
    "print(f\"Counterfactual times: {np.mean(counterfactual_times)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
